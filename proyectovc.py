# -*- coding: utf-8 -*-
"""ProyectoVC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Isa-q2TpgMXylbdZUV7yM7rxSbuSEWEF

Las diferentes librerias que se utilizan.
"""

import numpy as np
import cv2 as cv
from google.colab.patches import cv2_imshow
import copy
from skimage import measure
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg16 import decode_predictions
from keras.applications.vgg16 import VGG16

"""se carga el modelo."""

model = VGG16()

"""funcion para segmentar la imagen restando una imagen de fondo con una imagen con el oobjeto."""

def SEGF(IMGF, IMGNF):##recibe 2 imagenes RGB
  i1=IMGF.astype(np.int16)
  i2=IMGNF.astype(np.int16)
  i3=abs(i2-i1)
  i4=np.dot(i3[...,:3], [0.299, 0.587, 0.144])
  (thresh, R) = cv.threshold(i4, 20, 255, cv.THRESH_BINARY)
  return R ##regresa una matriz de imagen en B&W habiendo restado una de otra

"""funcion que genera una lista con las coordenadas de los puntso continuos simerpe y cuando superen un umbral."""

def GenerarLista(IMG, IMG2, PARAM): ##recibe 2 imagenes, una Bakcground (IMG) y otra Foreground (IMG2)
  IR = SEGF(IMG, IMG2)
  lbl= measure.label(IR)
  li = measure.regionprops(lbl)
  li2 = []
  cont = 0
  ref = PARAM+1
  while(ref>PARAM):
    z = np.zeros(len(li))
    for x in range(len(li)):
      z[x]=len(li[x].coords)
      i = 0
    for n in range(len(z)):
      if (z[n]==max(z)):
        i = n
    if (li != []):
      ref = max(z)
    else:
      ref = -1
    if (ref > PARAM):
      li2.append(li[i])
      li.pop(i)
      #print(ref)
      cont = cont+1
    else:
      break
  return li2 ##retorna una lista con las coordenadas de los objetos en movimiento

"""funcion que genera 2 listas, siedo la primera una lista con las imagenes que muestren algun objeto de interes y la segunda, una lista con coordenadas utiles para dibujar el contorno de las imagenes recortadas en las imagenes completas de cada frame."""

def EXTRAER(IMG, IMG2, PARAM):##recibe una imagen de backforund, la de foreground y un parametro
  lista = GenerarLista(IMG, IMG2, PARAM)
  Rlist = []
  Clist = []
  for ind in range(len(lista)):
    minx=0
    maxx=0
    miny=0
    maxy=0
    lx = []
    ly = []
    minx=min(lista[ind].coords[:, 0])
    maxx=max(lista[ind].coords[:, 0])
    miny=min(lista[ind].coords[:, 1])
    maxy=max(lista[ind].coords[:, 1])
    Clist.append([maxx, minx, maxy, miny])
    nueva = np.zeros([maxx-minx, maxy-miny, 3])
    for x in range(maxx-minx):
      for y in range(maxy-miny):
        nueva[x][y][:] = IMG2[minx+x][miny+y][:]
    Rlist.append(nueva)
  return Rlist, Clist

"""funcion que dibuja en una imagen(frame) algun texto sobre un recuadro sobre un objeto de interes."""

def DRAW(IMG, LST, TXT):
  img = copy.deepcopy(IMG)
  text = copy.deepcopy(img)
  rectan = copy.deepcopy(img)
  rectan = cv.rectangle(img, (LST[3], LST[1]), (LST[2], LST[0]), (255,0,0),1)
  font = cv.FONT_HERSHEY_SIMPLEX
  text = cv.putText(rectan,TXT,(LST[3]+(int((LST[1])/2)), LST[1]-6),font,1/3,(255,0,0),1,cv.LINE_AA )
  return text

"""aqui se captura el video con open cv"""

vidcap = cv.VideoCapture('a_perro.MOV')

"""aqui se obtiene cada frame del video."""

success,image = vidcap.read()
count = 0
while success:
  cv.imwrite("frame%d.jpg" % count, image)          
  success,image = vidcap.read()
  ##print('Read a new frame: ', success)
  count += 1

"""En este espacio se ejecutan todas las funciones para obtener una lista que guarda los frames del video modificados con el marco y la prediccion sobre el objeto de interes."""

A = cv.imread("frame1.jpg",1)
images = []
u = []
y = []
for x in range(count):
  B = cv.imread("frame"+str(x)+".jpg",1)
  u.append(B)
  y.append(B)
  v, c = EXTRAER(A, B, 1100)
  if (v!=[]):
    for t in range(len(c)):
      width = 224
      height = 224
      dim = (width, height)
      image = cv.resize(v[t], dim, interpolation = cv.INTER_AREA)
      image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
      image = preprocess_input(image)
      yhat = model.predict(image)
      label = decode_predictions(yhat)
      label = label[0][0]
      txt = ('%s (%.2f%%)' % (label[1], label[2]*100))
      y[x] = DRAW(u[x], c[t], txt)
    images.append(y[x])
  else:
    images.append(B)

"""En este espacio crea el video utilizando cada frame obtenido previamente."""

x, y, z = images[0].shape
video = cv.VideoWriter("a_video.avi", cv.VideoWriter_fourcc(*'XVID'), 28, (y,x))
for image in images:
    video.write(image)

"""aqui se puede revisar frame por frame ara ver que se ejecuto exitosamente."""

cv2_imshow(images[170])